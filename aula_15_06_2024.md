## Conceitos introdutórios

- Arquitetura Vertical →  Refere-se a uma estrutura onde os dados e os processos são empilhados em camadas, com cada camada sendo responsável por uma função específica.
  - Uso doméstico
  - Personal Computer
- Arquitetura Horizontal → Refere-se a uma estrutura onde os componentes são distribuídos horizontalmente, muitas vezes em servidores diferentes, e cada componente realiza uma parte do processamento.
  - Escalabilidade e flexibilidade aumentadas, já que componentes podem ser adicionados ou removidos sem afetar o sistema como um todo.
  - Baixo custo
  - Usado no meio corporativo

- Cluster
  - Rede

- Hadoop
  - Ferramenta de clusterização

## Apache Beam
  - Apache Beam é um modelo unificado de programação para definir e executar pipelines de processamento de dados em batch e streaming.
  
  - Arquitetura
    - Modelo de programação de código aberto
    - Biblioteca de construção de pipelines
    - Processamente de dados **paralelos** e **distribuidos**.
    - DSL (Linguagem de Domínio Específico)

  - Característica
    - Modelo Unificado: Permite escrever pipelines de dados que podem ser executados em vários motores de processamento, como Apache Flink, Apache Spark, e Google Cloud Dataflow, entre outros.
    - Flexibilidade: Suporta diferentes fontes de dados e métodos de processamento.
    - Pipelines Portáveis: Os pipelines escritos com Beam são independentes do motor de execução, facilitando a migração entre diferentes plataformas.
    - APIs de Alto Nível: Fornece APIs em várias linguagens de programação, incluindo Java, Python e Go.
    - Processamento de Streaming e Batch: Suporta tanto processamento de dados em tempo real (streaming) quanto processamento de dados históricos (batch).
    - Portabilidade: Pode transportar de cloud para outra. Por isso, tem que suportar várias linguagens.

  - Vantagens
    - Experiência e preferência do desenvolvedor: Suporte para várias linguagens de programação, incluindo Java, Python e Go, permite que os desenvolvedores escolham a linguagem com a qual estão mais confortáveis.
    - Ecossistema e bibliotecas disponíveis: Beam fornece uma ampla gama de transformações integradas, como ParDo, GroupByKey, Combine, e Windowing, que permitem manipulações complexas de dados.
    - Integração com outros sistemas: Beam pode ser executado em vários motores de processamento como Apache Flink, Apache Spark, Google Cloud Dataflow, e Samza, permitindo flexibilidade na escolha do ambiente de execução.
    - Desempenho e escalabilidade: Beam permite que os motores de execução otimizem automaticamente os pipelines para desempenho e escalabilidade, aproveitando a capacidade de processamento paralelo e distribuído dos motores subjacentes.
    - Suporte à plataforma de execução: Os pipelines criados com Apache Beam são portáveis entre diferentes motores de execução, permitindo flexibilidade na escolha da infraestrutura.

  - Batch processing -> Batch processing é a execução de um conjunto de tarefas de processamento de dados em blocos ou lotes, em vez de tratar os dados em tempo real.
    - Pipelines em lote: Pipelines em lote são fluxos de processamento de dados que operam em grandes volumes de dados acumulados e são executados periodicamente.
    - PCollections: PCollections são coleções imutáveis de dados em Apache Beam que representam tanto dados em lote quanto fluxos contínuos de dados, servindo como contêineres para os elementos processados pelos pipelines.
    - Transformações de pardo: Transformações de ParDo são operações de processamento em Apache Beam que aplicam uma função definida pelo usuário a cada elemento de uma PCollection, permitindo a transformação e manipulação dos dados.
    - Fontes e destinos: Fontes e destinos em Apache Beam referem-se aos conectores que permitem a leitura de dados de sistemas de origem, como bancos de dados ou filas de mensagens, e a escrita de dados em sistemas de destino, como armazenamento em nuvem ou sistemas de análise.

  - Stream processing -> Processo dados na medida que eles ocorrem. Stream processing é o processamento de dados em tempo real, à medida que eles são gerados e recebidos, permitindo análises e ações imediatas.
    - PCollections (coleção de processamento): PCollections são coleções imutáveis de dados em Apache Beam que podem representar tanto dados em lote quanto dados de fluxo contínuo, servindo como base para operações de processamento.
    - Transformações de janela: Transformações de janela são técnicas de segmentação de dados em fluxos contínuos, permitindo o processamento e a análise de dados em intervalos de tempo ou condições específicas.
    - Event time e process time: Event time refere-se ao momento em que um evento ocorreu no mundo real, enquanto process time é o momento em que o evento é processado pelo sistema.
    - Pardo em modo contínuo: ParDo em modo contínuo aplica uma função definida pelo usuário a cada elemento de uma PCollection em tempo real, permitindo a transformação contínua dos dados em fluxo.
    - Triggers e acumulação de resultados: Triggers são mecanismos que determinam quando os resultados intermediários de uma janela devem ser emitidos, enquanto a acumulação de resultados refere-se ao armazenamento e combinação desses resultados ao longo do tempo.
      - Triggers x Schedule: Um é feito no ambiente em nuvem, outro não.
    - Runners de stream processing: Runners de stream processing são motores de execução que suportam a execução de pipelines de processamento contínuo em Apache Beam, como Apache Flink, Apache Spark e Google Cloud Dataflow.
      - Faze que definimos um ETL ou ELT.
     
  - Apache Beam Model
    - Modelo de programação unificado para construir pipelines de processamento de dados em larga escala.      
